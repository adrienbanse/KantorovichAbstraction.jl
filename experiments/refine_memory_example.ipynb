{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement the section III.C of [BRAJ23] (whose pdf can be found [here](https://adrienbanse.github.io/assets/pdf/cdc23_extended.pdf)).\n",
    "\n",
    "[BRAJ23] Adrien Banse, Licio Romao, Alessandro Abate, Raphaël M. Jungers, Data-driven abstractions via adaptive refinements and a Kantorovich metric [extended version]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module KantorovichAbstraction.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Main.KantorovichAbstraction"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We first include the implemented algorithms\n",
    "include(joinpath(@__DIR__, \"../src/KantorovichAbstraction.jl\"))\n",
    "K = KantorovichAbstraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Adaptive refinement of a dynamical system"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: We first define the dynamical system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We define the transfer function\n",
    "function F(x::Vector{Float64})\n",
    "    if x[1] >= 1.\n",
    "        return x\n",
    "    elseif x[2] <= .5\n",
    "        return [.5 * x[1]  + .5, x[2] + .5]\n",
    "    elseif x[1] >= .5\n",
    "        return [x[1] - .5, x[2]]\n",
    "    elseif x[2] >= .75\n",
    "        return [2. * x[1] + 1., 4. * (x[2] - .75)]\n",
    "    else\n",
    "        return x\n",
    "    end\n",
    "end\n",
    "\n",
    "# We define the output function\n",
    "H(x::Vector{Float64}) = x[1] >= 1. ? 0 : 1\n",
    "\n",
    "# We define other characteristics of the dynamical DynamicalSystem (see src/system.jl)\n",
    "dim = 2\n",
    "outputs = [0, 1]\n",
    "\n",
    "# And any initial (state, output) couple\n",
    "state = [0., 0.]\n",
    "output = H(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oracle (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We also have to define the oracle for the dynamical system\n",
    "# The oracle is a function that returns an abstraction as defined in [BRAJ23, Definition 6] given a partitioning\n",
    "# In [BRAJ23], we assume that one has access to such an oracle following [BRAJ23, Assumption 2]\n",
    "\n",
    "# We first define two function query_memory_system\n",
    "# The first one returns the measure of a given partition\n",
    "# The second returns the proportion of a partition that jumps to another partition\n",
    "# They respectively give μ_w and P_{w1, w2} in [BRAJ23, Definition 6]\n",
    "not(c::Int) = c == 0 ? 1 : 0\n",
    "function query_memory_system(init::Vector{Int})::Float64\n",
    "    res_dict = Dict(\n",
    "        0 => 1 / 2,\n",
    "        1 => Dict(\n",
    "            0 => 1 / 8,\n",
    "            1 => Dict(\n",
    "                0 => 1 / 7,\n",
    "                1 => Dict(\n",
    "                    0 => 1 / 3,\n",
    "                    1 => 2 / 3\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    function return_from_res(dict::Dict, init::Vector{Int}, agg::Float64)\n",
    "        l = length(init)\n",
    "        if l == 0 \n",
    "            return agg\n",
    "        end\n",
    "        c = init[1]\n",
    "        if typeof(dict[c]) <: Dict\n",
    "            return return_from_res(dict[c], init[2:l], agg * (1 - dict[not(c)]))\n",
    "        else\n",
    "            return dict[c] * agg\n",
    "        end\n",
    "    end\n",
    "    if length(init) > 1\n",
    "        for (c1, c2) = zip(init[1:length(init) - 1], init[2:length(init)])\n",
    "            if c1 == 0 && c2 == 1\n",
    "                return 0.\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if length(init) > 4 && init[1:4] == ones(4)\n",
    "        if init == ones(length(init))\n",
    "            return 1 / 4\n",
    "        else\n",
    "            return 0.\n",
    "        end\n",
    "    end\n",
    "    return return_from_res(res_dict, init, 1.)\n",
    "end\n",
    "function query_memory_system(from::Vector{Int}, to::Vector{Int})::Float64\n",
    "    p_from = query_memory_system(from)\n",
    "    p_to = query_memory_system(to)\n",
    "    if p_from == 0. || p_to == 0.\n",
    "        return 0.\n",
    "    end\n",
    "    from_future = from[2:length(from)]\n",
    "    shortest = min(length(from_future), length(to))\n",
    "    if from_future[1:shortest] == to[1:shortest]\n",
    "        if length(from_future) >= length(to)\n",
    "            return 1.\n",
    "        else\n",
    "            inter = vcat([from[1]], to)\n",
    "            return query_memory_system(inter) / p_from\n",
    "        end\n",
    "    else\n",
    "        return 0.\n",
    "    end\n",
    "end\n",
    "\n",
    "# And finally we define the corresponding oracle\n",
    "function oracle(W::Vector{Vector{Int}})\n",
    "    S = [K.PartitionState(w) for w = W]\n",
    "    μ = Dict{K.PartitionState, Float64}()\n",
    "    P = Dict{Tuple{K.PartitionState, K.PartitionState}, Float64}()\n",
    "    L = Dict{K.PartitionState, Int}()\n",
    "    for s_from = S\n",
    "        μ[s_from] = query_memory_system(K.id(s_from))\n",
    "        L[s_from] = K.id(s_from)[1]\n",
    "        for s_to = S\n",
    "            P[s_from, s_to] = query_memory_system(K.id(s_from), K.id(s_to))\n",
    "        end\n",
    "    end\n",
    "    labels = [0, 1]\n",
    "    return K.MarkovChain{K.PartitionState}(S, P, μ, labels, L)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.KantorovichAbstraction.DynamicalSystem{typeof(F), typeof(H), typeof(oracle)}(F, H, 2, [0.0, 0.0], [0, 1], 1, oracle)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We are now able to define the dynamical system\n",
    "system = K.DynamicalSystem(F, H, dim, state, outputs, output, oracle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Use the REFINE algorithm as defined in [BRAJ23, Algorithm 2] to create a data-driven adaptive refinement abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k = 0) Current abstraction:\n",
      "Markov Chain with states Main.KantorovichAbstraction.PartitionState[[0], [1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k = 1) Current abstraction (chosen with d = 0.0015200741576384842):\n",
      "Markov Chain with states Main.KantorovichAbstraction.PartitionState[[0], [1, 0], [1, 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k = 2) Current abstraction (chosen with d = 0.005912370617181118):\n",
      "Markov Chain with states Main.KantorovichAbstraction.PartitionState[[0], [1, 0], [1, 1, 0], [1, 1, 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k = 3) Current abstraction (chosen with d = 0.003906247549900491):\n",
      "Markov Chain with states Main.KantorovichAbstraction.PartitionState[[0], [1, 0], [1, 1, 0], [1, 1, 1, 0], [1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# We will now use our function refine defined in src/abstraction.jl to \n",
    "N = typemax(Int) \n",
    "ε = 1e-5\n",
    "\n",
    "_ = K.refine(system, N, ε; verbose = true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with $N = \\infty$, the algorithm stops at $k = 3$, and therefore the last abstraction has the same behaviour as the dynamical system following [BRAJ23, Proposition 1]. \\  \n",
    "We recover the values in [BRAJ23, Table I]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Application to controller design"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we solve MDPs as explained in [BRAJ3, Section III.C] for Example 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Distributions\n",
    "using POMDPs, QuickPOMDPs, POMDPModelTools, POMDPSimulators, QMDP, DiscreteValueIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We first define actions, reward and a discount factor\n",
    "\n",
    "actions = [0, 1/4, 1/2]\n",
    "reward = function (s, a) return s == 0 ? 1. : 0. end\n",
    "discount = .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve_MDP_abstraction (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We now create a function that will solve the MDP defined by a set of states, some initial probabilities on the states and a transition function transition(s, a) corresponding to the probability to go to another state from state s, with action a\n",
    "# See POMDPs.jl doc for more information\n",
    "\n",
    "function solve_MDP_abstraction(\n",
    "    states, \n",
    "    initial_probs, \n",
    "    transition;\n",
    "    verbose = false\n",
    ")\n",
    "    m = QuickMDP(\n",
    "        states = states,\n",
    "        actions = actions,\n",
    "        initialstate = SparseCat(states, initial_probs),\n",
    "        discount = discount,\n",
    "        transition = transition,\n",
    "        reward = reward\n",
    "    )\n",
    "    solver = ValueIterationSolver(max_iterations=10000)\n",
    "    policy = solve(solver, m)\n",
    "    w = 0\n",
    "\n",
    "    if verbose\n",
    "        println(\"-- Result --\")\n",
    "        for (i, s) = enumerate(K.states(m))\n",
    "            println(\"V($s) = $(value(policy, s))\")\n",
    "            w += initial_probs[i] * value(policy, s)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define the transitions of the MDP corresponding to the result of the REFINE algorithm above. \\\n",
    "For each partitioning, we found the transition function on paper, and explicitely write it here. \\\n",
    "For each partitionnig, we find the optimal policty thanks to our function to solve MDPs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueIterationPolicy:\n",
       " 0 -> 0.0\n",
       " 1 -> 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states_0 = [0, 1]\n",
    "initial_probs = [1/2, 1/2]\n",
    "function _transition(s, a)\n",
    "    res = Dict(\n",
    "        0 => Deterministic(0), \n",
    "        1 => SparseCat([1, 0], [7/8, 1/8])\n",
    "    )\n",
    "    return res[s]\n",
    "end\n",
    "p_0 = solve_MDP_abstraction(states_0, initial_probs, _transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueIterationPolicy:\n",
       " 0 -> 0.0\n",
       " 10 -> 0.0\n",
       " 11 -> 0.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states_1 = [0, 10, 11]\n",
    "initial_probs = [1/2, 1/16, 7/16]\n",
    "function _transition(s, a)\n",
    "    if a == 0\n",
    "        res = Dict(\n",
    "            0 => Deterministic(0), \n",
    "            10 => Deterministic(0),\n",
    "            11 => SparseCat([11, 10], [6/7, 1/7])\n",
    "        )\n",
    "        return res[s]\n",
    "    end\n",
    "    res = Dict(\n",
    "        0 => Deterministic(0),\n",
    "        10 => Deterministic(11),\n",
    "        11 => SparseCat([11, 10, 0], [5/7, 1/7, 1/7])\n",
    "    )\n",
    "    return res[s]\n",
    "end\n",
    "p_1 = solve_MDP_abstraction(states_1, initial_probs, _transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueIterationPolicy:\n",
       " 0 -> 0.0\n",
       " 10 -> 0.0\n",
       " 110 -> 0.0\n",
       " 111 -> 0.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states_2 = [0, 10, 110, 111]\n",
    "initial_probs = [1/2, 1/16, 1/16, 3/8]\n",
    "function _transition(s, a)\n",
    "    if a == 0\n",
    "        res = Dict(\n",
    "            0 => Deterministic(0),\n",
    "            10 => Deterministic(0),\n",
    "            110 => Deterministic(10),\n",
    "            111 => SparseCat([111, 110], [2/3, 1/3])\n",
    "        )\n",
    "        return res[s]\n",
    "    end\n",
    "    if a == 1/4\n",
    "        res = Dict(\n",
    "            0 => Deterministic(0),\n",
    "            10 => Deterministic(111),\n",
    "            110 => Deterministic(111),\n",
    "            111 => SparseCat([111, 110, 10, 0], [1/3, 1/3, 1/6, 1/6])\n",
    "        )\n",
    "        return res[s]\n",
    "    end\n",
    "    if a == 1/2\n",
    "        res = Dict(\n",
    "            0 => Deterministic(0),\n",
    "            10 => Deterministic(110),\n",
    "            110 => Deterministic(110),\n",
    "            111 => SparseCat([111, 10, 0], [2/3, 1/6, 1/6])\n",
    "        )\n",
    "        return res[s]\n",
    "    end\n",
    "end\n",
    "p_2 = solve_MDP_abstraction(states_2, initial_probs, _transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueIterationPolicy:\n",
       " 0 -> 0.0\n",
       " 10 -> 0.0\n",
       " 110 -> 0.0\n",
       " 1110 -> 0.5\n",
       " 1111 -> 0.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states_3 = [0, 10, 110, 1110, 1111]\n",
    "initial_probs = [1/2, 1/16, 1/16, 1/8, 2/8]\n",
    "function _transition(s, a)\n",
    "    if a == 0\n",
    "        res = Dict(\n",
    "            0 => Deterministic(0),\n",
    "            10 => Deterministic(0),\n",
    "            110 => Deterministic(10),\n",
    "            1110 => Deterministic(110),\n",
    "            1111 => Deterministic(1111),\n",
    "        )\n",
    "        return res[s]\n",
    "    end\n",
    "    if a == 1/4\n",
    "        res = Dict(\n",
    "            0 => Deterministic(0),\n",
    "            10 => Deterministic(1111),\n",
    "            110 => Deterministic(1111),\n",
    "            1110 => Deterministic(1111),\n",
    "            1111 => SparseCat([110, 10, 0], [1/2, 1/4, 1/4])\n",
    "        )\n",
    "        return res[s]\n",
    "    end\n",
    "    if a == 1/2\n",
    "        res = Dict(\n",
    "            0 => Deterministic(0),\n",
    "            10 => Deterministic(110),\n",
    "            110 => Deterministic(110),\n",
    "            1110 => SparseCat([10, 0], [1/2, 1/2]),\n",
    "            1111 => Deterministic(1111)\n",
    "        )\n",
    "        return res[s]\n",
    "    end\n",
    "end\n",
    "p_3 = solve_MDP_abstraction(states_3, initial_probs, _transition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a controlled dynamical system corresponding to the optimal policies found above. \\\n",
    "For this, we first need to util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_in_partition (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function returns true if a given state x is in the partition \"state\" \n",
    "\n",
    "function is_in_partition(state::Vector{Int}, x::Vector{Float64}, sys::K.DynamicalSystem)\n",
    "    xp = copy(x)\n",
    "    for s = state\n",
    "        if (K.H(sys))(xp) != s \n",
    "            return false\n",
    "        end\n",
    "        xp = (K.F(sys))(xp)\n",
    "    end\n",
    "    return true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approximate_reward (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Given a controlled system, a discount factor, a reward function, a sample length L and a number of samples N, this function gives the corresponding approximated expected reward as in [BRAJ23, Equation (11)]\n",
    "\n",
    "function approximate_reward(\n",
    "    cont_system::K.ControlledDynamicalSystem, \n",
    "    discount::Float64, \n",
    "    reward::F, \n",
    "    L::Int, \n",
    "    N::Int\n",
    ") where F <: Function\n",
    "    global r_tot = 0\n",
    "    for n = 1:N\n",
    "        cont_system.system.state = [rand(Distributions.Uniform(0, 2)), rand(Distributions.Uniform(0, 1))]\n",
    "        cont_system.system.output = (K.H(cont_system))(K.state(cont_system))\n",
    "        local r = reward(K.output(cont_system), nothing)\n",
    "        for l = 1:(L - 1)\n",
    "            K.next!(cont_system)\n",
    "            r += discount^l * reward(K.output(cont_system), nothing)\n",
    "        end\n",
    "        r_tot += r\n",
    "    end\n",
    "    return r_tot / N\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each partitioning found by REFINE, we are able to define a corresponding controlled dynamical system (see [BRAJ23, Equation (12)]), \\\n",
    "and approximate the corresponding expected reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k = 0) Expected reward is 14.341482500000053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k = 1) Expected reward is 18.904444650000364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k = 2) Expected reward is 19.03577750000061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k = 3) Expected reward is 19.072816000000536\n"
     ]
    }
   ],
   "source": [
    "for (i, (p, states)) = enumerate(zip([p_0, p_1, p_2, p_3], [states_0, states_1, states_2, states_3]))\n",
    "    function control(x::Vector{Float64})\n",
    "        for s = states\n",
    "            parsed_state = [parse(Int64, a) for a = string(s, base=10)]\n",
    "            if is_in_partition(parsed_state, x, system)\n",
    "                x2 = (x[2] + action(p, s)) % 1\n",
    "                return [x[1], x2]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    cont_system = K.ControlledDynamicalSystem(system, control)\n",
    "    r = approximate_reward(cont_system, discount, reward, 1000, 5000) \n",
    "    println(\"(k = $(i-1)) Expected reward is $r\")\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recover the values in [BRAJ23, Table II] (up to randomness). \\\n",
    "One can see that the expected reward increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
